{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 14 files: 100%|██████████| 14/14 [30:17<00:00, 129.84s/it]  \n",
      "Loading checkpoint shards: 100%|██████████| 14/14 [01:23<00:00,  5.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"Qwen/QwQ-32B\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,            # enable 4-bit (QLoRA-style) weights\n",
    "    bnb_4bit_quant_type=\"nf4\",    # NF4 gives the best accuracy for most LLMs\n",
    "    bnb_4bit_use_double_quant=True, # optional: second quantisation pass to save ~0.4 bits/param\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # faster matmuls on recent GPUs; fall back to float16 if needed\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",      # let Accelerate split layers across all visible GPUs\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=\"auto\",     # keeps non-linear layers in their original dtype\n",
    "    trust_remote_code=True  # Qwen models need their custom code\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/TensorCompare.cu:112: _assert_async_cuda_kernel: block: [0,0,0], thread: [0,0,0] Assertion `probability tensor contains either `inf`, `nan` or element < 0` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      5\u001b[39m text = tokenizer.apply_chat_template(\n\u001b[32m      6\u001b[39m     messages,\n\u001b[32m      7\u001b[39m     tokenize=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      8\u001b[39m     add_generation_prompt=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m model_inputs = tokenizer([text], return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(model.device)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m generated_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32768\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m generated_ids = [\n\u001b[32m     18\u001b[39m     output_ids[\u001b[38;5;28mlen\u001b[39m(input_ids):] \u001b[38;5;28;01mfor\u001b[39;00m input_ids, output_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_inputs.input_ids, generated_ids)\n\u001b[32m     19\u001b[39m ]\n\u001b[32m     21\u001b[39m response = tokenizer.batch_decode(generated_ids, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/prm/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/prm/lib/python3.12/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/prm/lib/python3.12/site-packages/transformers/generation/utils.py:3602\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3600\u001b[39m     probs = nn.functional.softmax(next_token_scores, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m   3601\u001b[39m     \u001b[38;5;66;03m# TODO (joao): this OP throws \"skipping cudagraphs due to ['incompatible ops']\", find solution\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3602\u001b[39m     next_tokens = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m   3603\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3604\u001b[39m     next_tokens = torch.argmax(next_token_scores, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How many r's are in the word \\\"strawberry\\\"\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, PreTrainedTokenizer\n",
    "from collections import defaultdict, deque\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm, trange\n",
    "import wandb\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "from collections import Counter\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRMConfig:\n",
    "    \"\"\"Configuration class for PRM hyperparameters and settings\"\"\"\n",
    "    # MC config\n",
    "    model_name:             str = \"Qwen/Qwen2.5-Math-7B\"\n",
    "    max_new_tokens:         int = 384\n",
    "    num_rollouts:           int = 8\n",
    "    reward_threshold:       float = 0.5\n",
    "    samples_per_question:   int = 1\n",
    "    use_llm:                bool = True\n",
    "    use_contri:             bool = False\n",
    "    # PRM Model config\n",
    "    hidden_size:        int = 512\n",
    "    num_layers:         int = 3\n",
    "    dropout:            float = 0.2\n",
    "    # PRMTrainer config\n",
    "    batch_size:         int = 12\n",
    "    learning_rate:      float = 5e-4\n",
    "    num_workers:        int = 4\n",
    "    weight_decay:       float = 1e-2\n",
    "    lr_scheduler:       str   = \"cosine\"\n",
    "    dataset_size:       int = 0\n",
    "    warmup_steps:       int   = 22\n",
    "    grad_clip:          float = 1.0\n",
    "    epochs:             int = 25\n",
    "    # Misc config\n",
    "    use_wandb:          bool = True\n",
    "    wandb_project:      str = \"mc_prm\"\n",
    "    run_name:           str = \"test_gsm8k_100_ori_mse\"\n",
    "    checkpoint_dir:     str = \"./checkpoints/gsm8k/ori_mse\"\n",
    "    seed:               int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                        UTILITY: ANSWER NORMALISATION                         #\n",
    "################################################################################\n",
    "import sympy as sp\n",
    "\n",
    "def _strip_markup(ans: str) -> str:\n",
    "    \"\"\"Remove common LaTeX/markup & variable tags.\"\"\"\n",
    "    # # Remove LaTeX inline math wrappers \\( … \\) or \\[ … \\]\n",
    "    # ans = re.sub(r\"\\\\[\\[(](.*?)[\\\\\\])]\", r\"\\1\", ans)\n",
    "    # # Remove \\boxed{…}\n",
    "    # ans = re.sub(r\"\\\\boxed\\{([^}]*)\\}\", r\"\\1\", ans)\n",
    "    ans = re.sub(r\"\\\\\\[.*?\\\\\\]\", \"\", ans)\n",
    "    ans = re.sub(r\"\\$\\$.*?\\$\\$\", \"\", ans)\n",
    "    # Remove inline LaTeX: \\( ... \\) and $...$\n",
    "    ans = re.sub(r\"\\\\\\((.*?)\\\\\\)\", r\"\\1\", ans)\n",
    "    ans = re.sub(r\"\\$(.*?)\\$\", r\"\\1\", ans)\n",
    "    # Remove \\boxed{...}\n",
    "    ans = re.sub(r\"\\\\boxed\\s*{([^}]*)}\", r\"\\1\", ans)\n",
    "    # Remove LaTeX commands like \\text{...}, \\frac{...}, etc.\n",
    "    ans = re.sub(r\"\\\\[a-zA-Z]+\\s*(\\{[^{}]*\\})?\", \"\", ans)\n",
    "    # Remove variable assignments like \"y =\" or \"x=\" at start\n",
    "    ans = re.sub(r\"^[a-zA-Z]\\s*=\\s*\", \"\", ans)\n",
    "    # Trim outer $ … $ if present\n",
    "    ans = ans.strip()\n",
    "    if ans.startswith(\"$\") and ans.endswith(\"$\"):\n",
    "        ans = ans[1:-1]\n",
    "    return ans.strip()\n",
    "\n",
    "def _sanitize(text: str) -> str:\n",
    "    \"\"\"Normalise a candidate answer string for comparison.\"\"\"\n",
    "    text = _strip_markup(text)\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"[\\s\\.;:,]+$\", \"\", text)     # trailing punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)              # collapse spaces\n",
    "    return text\n",
    "\n",
    "def _to_float(expr: str) -> Optional[float]:\n",
    "    try:\n",
    "        return float(eval(expr.replace(\"^\", \"**\")))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _numeric_equiv(a: str, b: str) -> bool:\n",
    "    \"\"\"Return True if `a` and `b` are numerically equivalent or exact match.\"\"\"\n",
    "    a_clean, b_clean = map(_sanitize, (a, b))\n",
    "    if a_clean == b_clean:\n",
    "        return True\n",
    "\n",
    "    # Attempt simple numeric evaluation\n",
    "    a_val, b_val = _to_float(a_clean), _to_float(b_clean)\n",
    "    if a_val is not None and b_val is not None:\n",
    "        return math.isclose(a_val, b_val, rel_tol=1e-6)\n",
    "\n",
    "    if sp is not None:\n",
    "        try:\n",
    "            a_expr = sp.sympify(a_clean.replace(\"^\", \"**\"))\n",
    "            b_expr = sp.sympify(b_clean.replace(\"^\", \"**\"))\n",
    "            return sp.simplify(a_expr - b_expr) == 0\n",
    "        except Exception:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "def system_prompt(type):\n",
    "    prompt = \"\"\n",
    "    if type == \"sample\":\n",
    "        prompt = \"\"\"You are a math-problem expert. Your task is to complete the step-by-step solution for the problem provided. Write each reasoning step on its own line in the exact form \\\"Step k: [your reasoning step]\\n\\\", numbering start from Step 1. When the final answer is obtained, write exactly one final line, \\\"Answer: [Final answer]\\\". Do NOT add explanations, extra steps, or any text after the \"Answer:\" line.\n",
    "\n",
    "**Format Guide**: (You MUST write \"Step \" before numbering the step.)\n",
    "Step 1: [Step 1 reasoning]\\n\n",
    "Step 2: [Step 2 reasoning]\\n\n",
    "...\n",
    "Step k: [Step k reasoning]\\n\n",
    "...\n",
    "Answer: [Final answer]\n",
    "\n",
    "Format Guide with Examples:\n",
    "<Example 1>\n",
    "Problem: Find the sum of the first 8 positive even integers.\n",
    "Step 1: The first 8 even integers are 2, 4, 6, 8, 10, 12, 14, 16.\n",
    "Step 2: Use the formula for an arithmetic series: S = n·(first + last)/2.\n",
    "Step 3: Substitute n=8, first=2, last=16 to get S = 8·(2+16)/2 = 8·9 = 72.\n",
    "Answer: 72\n",
    "\n",
    "<Example 2>\n",
    "Problem: Determine the next number in the sequence 2, 4, 8, 16.\n",
    "Step 1: Notice each term is obtained by multiplying the previous term by 2.\n",
    "Step 2: Multiply 16 by 2, 16 * 2 = 32.\n",
    "Answer: 32\n",
    "\n",
    "Follow the FORMAT GUIDE structure exactly. Generate rationales step-by-step, not directly to the final answer. **Do NOT** write anything after the final 'Answer:' line. Always start stepwise reasoning with \"Step {i-th}: \" form.\"\"\"\n",
    "    if type == \"rollout\":\n",
    "        prompt = \"\"\"You are a math problem-solving expert. Continue solving the given problem step by step, strictly following the required format. Each new step must begin with \\\"Step k+1: ...\\\", \\\"Step k+2:...\\\", and so on, continuing from the last given step number. When the final answer is reached, write only one final line starting with: \\\"Answer: [Final Answer]\\\". Do not add any explanations, extra commentary, or additional text after the \"Answer:\" line. Your output must follow this exact step-by-step format with no deviations.\n",
    "\n",
    "**Format Guide**: (You MUST write \"Step \" before numbering the step.)\n",
    "Step 1: [Step 1 reasoning]\\n\n",
    "Step 2: [Step 2 reasoning]\\n\n",
    "...\n",
    "Step k: [Step k reasoning]\\n\n",
    "Continue and finish the solution:\n",
    "Step k+1: [Step k+1 reasoning]\\n\n",
    "...\n",
    "Answer: [Final answer]\n",
    "\n",
    "Format Guide with Examples:\n",
    "<Example 1>\n",
    "Current solution steps:\n",
    "Problem: Find the sum of the first 8 positive even integers.\n",
    "Step 1: The first 8 even integers are 2, 4, 6, 8, 10, 12, 14, 16.\n",
    "Step 2: Use the formula for an arithmetic series: S = n·(first + last)/2.\n",
    "Continue and finish the solution:\n",
    "Step 3: Substitute n=8, first=2, last=16 to get S = 8·(2+16)/2 = 8·9 = 72.\n",
    "Answer: 72\n",
    "\n",
    "<Example 2>\n",
    "Current solution steps:\n",
    "Problem: Determine the next number in the sequence 2, 4, 8, 16.\n",
    "Step 1: Notice each term is obtained by multiplying the previous term by 2.\n",
    "Continue and finish the solution:\n",
    "Step 2: Multiply 16 by 2, 16 * 2 = 32.\n",
    "Answer: 32\n",
    "\n",
    "Keep the reasoning steps precise and factual and complete the solution. Follow the FORMAT GUIDE structure exactly. **Do NOT** write anything after the final 'Answer:' line. Always start stepwise reasoning with \"Step {i-th}: \" form.\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Project‑level helpers \n",
    "from utils import _sanitize, _numeric_equiv, _strip_markup, _to_float, system_prompt\n",
    "from config import PRMConfig\n",
    "\n",
    "class MCReward:\n",
    "    STEP_PATTERN = re.compile(\n",
    "    r\"\"\"^[\\s>#*\\-]*          # optional markdown/bullet symbols\n",
    "        Step\\s*              # word 'Step' (case-insensitive)\n",
    "        (\\d+)                # capture step number\n",
    "        \\s*[:.\\-]            # separator (: . or -)\n",
    "    \"\"\",\n",
    "    re.IGNORECASE | re.VERBOSE,\n",
    "    )\n",
    "    ANSWER_PATTERN = re.compile(\n",
    "        r\"\"\"^[\\s>#*\\-]*          # optional markdown/bullet symbols\n",
    "            Answer               # word 'Answer'\n",
    "            \\s*[:.\\-]\\s*         # separator\n",
    "            (.+?)\\s*$            # capture everything after\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.MULTILINE | re.VERBOSE,\n",
    "    )\n",
    "    ## Masked rewards ##\n",
    "    OP_TOKENS = [\"add\", \"plus\", \"sum\", \"subtract\", \"minus\",\n",
    "             \"multiply\", \"times\", \"product\", \"divide\", \"quotient\"]\n",
    "    _MASK_PATTERN = re.compile(\n",
    "        r\"\"\"\n",
    "        (?:\n",
    "        # {ops_pattern}|                # operator patterns\n",
    "            \\b\\d+(?:\\.\\d+)?\\b         # integers / decimals\n",
    "          | \\b\\d+/\\d+\\b                 # simple fractions\n",
    "        #   | \\b[a-zA-Z]\\b                 # single‑letter variables\n",
    "        )\n",
    "        \"\"\",\n",
    "        re.VERBOSE,\n",
    "    )\n",
    "\n",
    "    def __init__(self, config: \"PRMConfig\", model, tokenizer):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.llm = LLM(\n",
    "            model=hf_model.name_or_path,     # 동일 체크포인트\n",
    "            dtype=\"float16\",                 # fp16 / bfloat16\n",
    "            tensor_parallel_size=torch.cuda.device_count(),  # 여러 GPU → 자동 shard\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "        self.sparams = SamplingParams(\n",
    "            max_tokens=config.max_new_tokens,\n",
    "            temperature=0.8,\n",
    "            top_p=0.8,\n",
    "            n=config.num_rollouts,          # 한번에 num_rollouts 샘플\n",
    "            # 필요 시 stop 토큰 추가\n",
    "        )\n",
    "\n",
    "    # Function to generate one or more step-by-step solutions for a given question.\n",
    "    def generate_solutions(self, question: str, sys_prompt: str, num_solutions: int):\n",
    "        prompt = f\"{sys_prompt}\\n\\n{question}\\n\"  # Prompt the model to start the step-by-step solution\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)\n",
    "        # Generate multiple solutions via sampling\n",
    "        outputs = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=self.config.max_new_tokens,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=num_solutions,\n",
    "            temperature=0.8,         # sampling temperature for diversity (adjust as needed)\n",
    "            top_p=0.8,               # top-p sampling for diversity\n",
    "            pad_token_id=self.tokenizer.eos_token_id  # pad token ID to avoid warning for some models\n",
    "        )\n",
    "        solutions = []\n",
    "        prompt_len = input_ids.shape[-1]\n",
    "        for i in range(num_solutions):\n",
    "            # Each output is the concatenation of the prompt and the generated completion.\n",
    "            generated_ids = outputs[i]\n",
    "            # Extract only the newly generated tokens (skip the prompt tokens).\n",
    "            gen_ids = generated_ids[prompt_len:]\n",
    "            text = self.tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
    "            solutions.append(text)\n",
    "            # print(f\"{i}-th Sampled Solutions:\",text)\n",
    "        return solutions\n",
    "    \n",
    "    def gsm8k_solutions(self, question: str, gold_solution: str):\n",
    "        # 1. Split lines *before* the final answer marker (#### …)\n",
    "        lines: List[str] = []\n",
    "        gold_answer: str = \"\"\n",
    "        _ANSWER_RE = re.compile(r\"####\\s*(.+?)\\s*$\")\n",
    "\n",
    "        for raw_ln in gold_solution.splitlines():\n",
    "            ln = raw_ln.strip()\n",
    "            if not ln:\n",
    "                continue  # skip empty\n",
    "            ans_match = _ANSWER_RE.match(ln)\n",
    "            if ans_match:\n",
    "                gold_answer = ans_match.group(1).strip()\n",
    "                break  # everything after #### is ignored\n",
    "            lines.append(ln)\n",
    "\n",
    "        if not gold_answer:\n",
    "            raise ValueError(\"Could not find final answer marker '#### <answer>' in gold_solution.\")\n",
    "\n",
    "        # 2. Prefix each explanatory line with \"Step i:\"\n",
    "        solution_steps = [f\"Step {i + 1}: {txt}\" for i, txt in enumerate(lines)]\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"solution\": solution_steps,\n",
    "            \"gold_answer\": gold_answer,\n",
    "        }\n",
    "\n",
    "    # Function to parse a solution text into steps and final answer.\n",
    "    def _extract_answer(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Try multiple heuristics / regexes to pull out an answer string.\"\"\"\n",
    "        # Primary regex (robust to Answer:, Answer ‑, etc.)\n",
    "        match = self.ANSWER_PATTERN.search(text)\n",
    "        if match:\n",
    "            return _sanitize(match.group(1))\n",
    "        \n",
    "        # Fallback 1: last non‑empty line if it looks simple / numeric\n",
    "        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "        if lines:\n",
    "            candidate = lines[-1]\n",
    "            if re.search(r\"\\d\", candidate):  # contains digit\n",
    "                return _sanitize(candidate)\n",
    "\n",
    "        # Fallback 2: look for last line that starts with 'Answer'\n",
    "        for line in reversed(text.splitlines()):\n",
    "            if line.strip().lower().startswith(\"answer\"):\n",
    "                return _sanitize(line.split(\"Answer\", 1)[-1])\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def parse_solution(self, solution_text: str):\n",
    "        \"\"\"Split each step to start with 'Step X:' and the answer to start with 'Answer:'.\"\"\"\n",
    "        steps = []\n",
    "        # Split by lines to identify steps and answer\n",
    "        for line in solution_text.splitlines():\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if self.STEP_PATTERN.match(line):\n",
    "                cleaned = re.sub(r'^[\\s>#*\\-]+', '', line)\n",
    "                steps.append(cleaned)\n",
    "            answer = self._extract_answer(solution_text)\n",
    "        return steps, answer\n",
    "    \n",
    "    # Function to estimate intermediate rewards for each step via rollouts.\n",
    "    def compute_step_rewards(self, question, sys_prompt, steps, gold_answer):\n",
    "        \"\"\"\n",
    "        For each prefix ending at a given step in 'steps', generate rollouts and compute the reward \n",
    "        (fraction of rollouts ending in the correct answer). Returns a list of reward values corresponding to each step.\n",
    "        \"\"\"\n",
    "        rewards = []\n",
    "        total_steps = len(steps)\n",
    "\n",
    "        # Pre‑encode static prefix (sys_prompt + question) once for efficiency\n",
    "        base_prompt = f\"{sys_prompt}\\n\\nProblem: {question}\\n\"\n",
    "        base_ids = self.tokenizer.encode(base_prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        for i in range(total_steps):\n",
    "            prefix_tokens = self.tokenizer.encode(\"\\n\".join(steps[: i + 1]) + \"\\n\", return_tensors=\"pt\").to(self.device) # steps up to current step i (0-indexed)\n",
    "            # Decide how to prompt the next part:\n",
    "            if i < total_steps - 1:\n",
    "                next_label = f\"Step {i + 2}:\"\n",
    "            else:\n",
    "                next_label = \"Answer:\"\n",
    "            cont_ids = self.tokenizer.encode(next_label, return_tensors=\"pt\").to(self.device)\n",
    "            # Build full prefix ids (avoid Python concat inefficiency by cat)\n",
    "            prefix_ids = torch.cat([base_ids, prefix_tokens, cont_ids], dim=-1)\n",
    "            rollout_outputs = self.model.generate(\n",
    "                prefix_ids,\n",
    "                max_new_tokens=self.config.max_new_tokens,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=self.config.num_rollouts,\n",
    "                temperature=0.8,\n",
    "                top_p=0.8,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "            new_token_start = prefix_ids.shape[-1] \n",
    "            # Check each rollout's final answer against the gold answer\n",
    "            correct_count = 0\n",
    "            for idx, seq in enumerate(rollout_outputs):\n",
    "                completion = self.tokenizer.decode(seq[new_token_start:], skip_special_tokens=True)\n",
    "                pred_answer = self._extract_answer(completion)\n",
    "                print(f\"[{i+1}-th Step, {idx}-th Original Rollout]\", completion, \"Pred Answer\", pred_answer)\n",
    "                if pred_answer is not None and _numeric_equiv(pred_answer, gold_answer):\n",
    "                    correct_count += 1\n",
    "            reward = correct_count / float(self.config.num_rollouts)\n",
    "            rewards.append(reward)\n",
    "        return rewards\n",
    "    \n",
    "    # Masked solution paths\n",
    "    def model_masking(self, text: str, *, max_new_tokens: int = 64) -> str:\n",
    "        prompt = \"In the sentence below, mask any word or expression that seems crucial for solving the math step. This may include key numbers, variables, or action words (like operations), but you should decide what matters. Replace each important item with '[MASKED]'. Keep everything else unchanged. Return ONE line.\\n\\nSentence: \\\"{sent}\\\"\\nRewritten:\".format(sent=text)\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        out_ids   = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.2, top_p=0.2,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "        )\n",
    "        return self.tokenizer.decode(out_ids[0][input_ids.shape[-1]:],\n",
    "                                     skip_special_tokens=True).strip()\n",
    "\n",
    "    def perturbed_step_rewards(self, question: str, sys_prompt: str, steps: List[str], gold_answer: str, use_llm: bool = True) -> List[float]:\n",
    "        \"\"\"Compute MC correctness rates *after masking* the current step.\n",
    "        Each step `i` is replaced with a *perturbed* version where important\n",
    "        tokens (numbers, fractions, single‑letter variables) are substituted by\n",
    "        the literal string ``[MASKED]``. All preceding steps remain intact.\n",
    "        \"\"\"\n",
    "        ptb_rewards: List[float] = []\n",
    "        total_steps = len(steps)\n",
    "        base_prompt = f\"{sys_prompt}\\n\\nProblem: {question}\\n\"\n",
    "        base_ids = self.tokenizer.encode(base_prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        for i in range(total_steps):\n",
    "            # 1. Perturb *only* step i\n",
    "            orig_step = steps[i] \n",
    "            step_match = re.match(r\"^[\\s>#*\\-]*Step\\s*\\d+\\s*[:.\\-]\\s*\", orig_step, flags=re.I)\n",
    "            prefix = step_match.group(0) if step_match else \"\"\n",
    "            # ② 나머지 부분(body)만 마스킹\n",
    "            body   = steps[i][len(prefix):]                       # 접두사 뒷부분\n",
    "            if use_llm:\n",
    "                masked_body = self.model_masking(body)\n",
    "            else:\n",
    "                masked_body = self._MASK_PATTERN.sub(\"[MASKED]\", body)\n",
    "            # ③ 접두사 + 마스킹된 body\n",
    "            masked_step = prefix + masked_body    \n",
    "            ptb_prefix_steps = steps[:i] + [masked_step]\n",
    "            # print(\"perturbed step:\", ptb_prefix_steps)\n",
    "\n",
    "            prefix_tokens = self.tokenizer.encode(\"\\n\".join(ptb_prefix_steps) + \"\\n\", return_tensors=\"pt\").to(self.device)\n",
    "            next_label = f\"Step {i + 2}:\" if i < total_steps - 1 else \"Answer:\"\n",
    "            cont_ids = self.tokenizer.encode(next_label, return_tensors=\"pt\").to(self.device)\n",
    "            prefix_ids = torch.cat([base_ids, prefix_tokens, cont_ids], dim=-1)\n",
    "\n",
    "            rollout_outputs = self.model.generate(\n",
    "                prefix_ids,\n",
    "                max_new_tokens=self.config.max_new_tokens,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=self.config.num_rollouts,\n",
    "                temperature=0.8,\n",
    "                top_p=0.8,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "            )\n",
    "            new_token_start = prefix_ids.shape[-1]\n",
    "            correct_count = 0\n",
    "            for idx, seq in enumerate(rollout_outputs):\n",
    "                completion = self.tokenizer.decode(seq[new_token_start:], skip_special_tokens=True)\n",
    "                pred_answer = self._extract_answer(completion)\n",
    "                print(f\"Masked [{i+1}-th Step, {idx}-th Rollout]\", completion, \"Pred Answer\", pred_answer)\n",
    "                if pred_answer is not None and _numeric_equiv(pred_answer, gold_answer):\n",
    "                    correct_count += 1\n",
    "            ptb_rewards.append(correct_count / float(self.config.num_rollouts))\n",
    "        return ptb_rewards\n",
    "\n",
    "    # Build datasets based on input datas\n",
    "    def build_datasets(self, problems: List):\n",
    "        dataset = []  # will hold the output list of dicts\n",
    "        for problem in problems:\n",
    "            question = problem[\"question\"]\n",
    "            # gold_answer = problem[\"gold_answer\"]\n",
    "            gold_answer = _sanitize(problem[\"gold_answer\"])\n",
    "            # Generate one or more solutions for this question\n",
    "            sample_prompt = system_prompt(\"sample\")\n",
    "            rollout_prompt = system_prompt(\"rollout\")\n",
    "            solutions = self.generate_solutions(question, sys_prompt=sample_prompt, num_solutions=self.config.samples_per_question)\n",
    "            \n",
    "            for sol_text in solutions:\n",
    "                steps, answer = self.parse_solution(sol_text)\n",
    "                # print(\"Parsed solution:\", steps, answer)\n",
    "                if answer is None: # If no answer was found in the solution (edge case), skip this solution\n",
    "                    continue\n",
    "                # 2. Compute *original* & *perturbed* per‑step rewards\n",
    "                # ----------------------------------------------------------\n",
    "                ori_rewards = self.compute_step_rewards(\n",
    "                    question=question,\n",
    "                    sys_prompt=rollout_prompt,\n",
    "                    steps=steps,\n",
    "                    gold_answer=gold_answer,\n",
    "                )\n",
    "                ptb_rewards = self.perturbed_step_rewards(\n",
    "                    question=question,\n",
    "                    sys_prompt=rollout_prompt,\n",
    "                    steps=steps,\n",
    "                    gold_answer=gold_answer,\n",
    "                )\n",
    "                # Align lengths (robustness)\n",
    "                if len(ptb_rewards) != len(ori_rewards):\n",
    "                    ptb_rewards = ptb_rewards[: len(ori_rewards)]\n",
    "                # contributions = [max(0, o - p) for o, p in zip(ori_rewards, ptb_rewards)]\n",
    "                contributions = [o - p for o, p in zip(ori_rewards, ptb_rewards)]\n",
    "                entry = {\n",
    "                    \"question\": question,\n",
    "                    \"completion\": steps,          # list[str] (Step i: ...)\n",
    "                    \"ori_rewards\": ori_rewards,    # list[float]\n",
    "                    \"ptb_rewards\": ptb_rewards,    # list[float]\n",
    "                    \"contributions\": contributions,  # ori − ptb\n",
    "                    \"answer\": answer,\n",
    "                    \"gold_answer\": gold_answer,\n",
    "                }\n",
    "                dataset.append(entry)\n",
    "        return dataset\n",
    "    \n",
    "    # Build datasets based on input datas\n",
    "    def build_datasets_gsm8k(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        _ANSWER_RE = re.compile(r\"####\\s*(.+?)\\s*$\")\n",
    "\n",
    "        rollout_pr = system_prompt(\"rollout\")\n",
    "        ds = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "        if take is not None:\n",
    "            ds = ds.shuffle(seed=self.config.seed).select(range(start, start+take))\n",
    "\n",
    "        csr, psr   = self.compute_step_rewards, self.perturbed_step_rewards\n",
    "        sanitize   = _sanitize\n",
    "        use_llm    = self.config.use_llm\n",
    "        dataset    = []\n",
    "        \n",
    "        for sample in tqdm(ds, desc=\"Building GSM-8K reward-dataset\"):\n",
    "            # ── (1) extract step solutions ──────────────────────────────────────────\n",
    "            q_txt   = sample[\"question\"]\n",
    "            g_sol   = sample[\"answer\"]\n",
    "            lines, gold_ans = [], None\n",
    "            for ln in g_sol.splitlines():\n",
    "                ln = ln.strip()\n",
    "                if not ln:\n",
    "                    continue\n",
    "                m = _ANSWER_RE.match(ln)\n",
    "                if m:\n",
    "                    gold_ans = sanitize(m.group(1))\n",
    "                    break\n",
    "                lines.append(ln)\n",
    "            if gold_ans is None:\n",
    "                raise ValueError(\"gold answer not found for sample\")\n",
    "            steps = [f\"Step {i+1}: {t}\" for i, t in enumerate(lines)]\n",
    "\n",
    "            # ── (2) compute rewards ───────────────────────────────────────────────────\n",
    "            ori = csr(q_txt, rollout_pr, steps, gold_ans)\n",
    "            ptb = psr(q_txt, rollout_pr, steps, gold_ans, use_llm)\n",
    "            if len(ptb) != len(ori):\n",
    "                ptb = ptb[: len(ori)]\n",
    "            contrib = [round(o - p, 4) for o, p in zip(ori, ptb)]\n",
    "\n",
    "            #  ── (3) Append entry ───────────────────────────────────────────\n",
    "            entry = {\n",
    "                    \"question\":      q_txt,\n",
    "                    \"completion\":    steps,\n",
    "                    \"ori_rewards\":   ori,\n",
    "                    \"ptb_rewards\":   ptb,\n",
    "                    \"contributions\": contrib,\n",
    "                    \"answer\":        gold_ans,\n",
    "                    \"gold_answer\":   gold_ans,\n",
    "                }\n",
    "            dataset.append(entry)\n",
    "            # print(entry)\n",
    "        return dataset\n",
    "\n",
    "    def build_datasets_math(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        \"\"\"\n",
    "        ① MATH 데이터셋 로드 → ② 정답·스텝 추출 → ③ 보상 계산 → ④ dict 리스트 반환\n",
    "        \"\"\"\n",
    "        boxed_re   = re.compile(r'\\\\boxed\\{(.+?)\\}', re.S)\n",
    "        sent_split = re.compile(r'\\.(?!\\d)(?=\\s|$)')   # 소수점·수식 내부 마침표 무시\n",
    "\n",
    "        rollout_prompt = system_prompt(\"rollout\")\n",
    "        ds = load_dataset(\"HuggingFaceTB/MATH\", \"all\", split=split)\n",
    "\n",
    "        # shuffle & take\n",
    "        if take is not None:\n",
    "            ds = ds.select(range(start, start+take))\n",
    "\n",
    "        # (alias) time optimize\n",
    "        csr, psr   = self.compute_step_rewards, self.perturbed_step_rewards\n",
    "        sanitize   = _sanitize\n",
    "        use_llm    = self.config.use_llm\n",
    "        dataset    = []\n",
    "\n",
    "        for sample in tqdm(ds, desc=\"Building MATH reward-dataset\"):\n",
    "            # ── (1) extract step solutions ──────────────────────────────────────────\n",
    "            full_sol   = sample[\"solution\"]\n",
    "            m          = boxed_re.search(full_sol)\n",
    "            gold_ans   = sanitize(m.group(1)) if m else None\n",
    "            sol_wo_box = boxed_re.sub(\"\", full_sol)\n",
    "            raw_steps  = [s.strip() for s in sent_split.split(sol_wo_box) if s.strip()]\n",
    "            steps      = [f\"Step {i+1}: {s}\" for i, s in enumerate(raw_steps)]\n",
    "\n",
    "            # ── (2) compute rewards ───────────────────────────────────────────────────\n",
    "            ori = csr(sample[\"problem\"], rollout_prompt, steps, gold_ans)\n",
    "            ptb = psr(sample[\"problem\"], rollout_prompt, steps, gold_ans, use_llm)\n",
    "            if len(ptb) != len(ori):\n",
    "                ptb = ptb[: len(ori)]\n",
    "            contrib = [round(o - p, 4) for o, p in zip(ori, ptb)]\n",
    "\n",
    "            # ── (3) Append entry ───────────────────────────────────────────\n",
    "            entry = {\n",
    "                \"question\":      sample[\"problem\"],\n",
    "                \"completion\":    steps,\n",
    "                \"ori_rewards\":   ori,\n",
    "                \"ptb_rewards\":   ptb,\n",
    "                \"contributions\": contrib,\n",
    "                \"answer\":        gold_ans,\n",
    "                \"gold_answer\":   gold_ans,\n",
    "                \"level\":         sample[\"level\"],\n",
    "                \"type\":          sample[\"type\"],\n",
    "            }\n",
    "            dataset.append(entry)\n",
    "            # print(entry)\n",
    "        return dataset\n",
    "\n",
    "    def build_datasets_math_vllm(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        from vllm import LLM, SamplingParams\n",
    "        boxed_re   = re.compile(r'\\\\boxed\\{(.+?)\\}', re.S)\n",
    "        sent_split = re.compile(r'\\.(?!\\d)(?=\\s|$)')   # 소수점·수식 내부 마침표 무시\n",
    "\n",
    "        rollout_prompt = system_prompt(\"rollout\")\n",
    "        ds = load_dataset(\"HuggingFaceTB/MATH\", \"all\", split=split)\n",
    "\n",
    "        # shuffle & take\n",
    "        if take is not None:\n",
    "            ds = ds.select(range(start, start+take))\n",
    "\n",
    "        # (alias) time optimize\n",
    "        csr, psr   = self.compute_step_rewards, self.perturbed_step_rewards\n",
    "        sanitize   = _sanitize\n",
    "        use_llm    = self.config.use_llm\n",
    "        dataset    = []\n",
    "\n",
    "        for sample in tqdm(ds, desc=\"Building MATH reward-dataset\"):\n",
    "            # ── (1) extract step solutions ──────────────────────────────────────────\n",
    "            full_sol   = sample[\"solution\"]\n",
    "            m          = boxed_re.search(full_sol)\n",
    "            gold_ans   = sanitize(m.group(1)) if m else None\n",
    "            sol_wo_box = boxed_re.sub(\"\", full_sol)\n",
    "            raw_steps  = [s.strip() for s in sent_split.split(sol_wo_box) if s.strip()]\n",
    "            steps      = [f\"Step {i+1}: {s}\" for i, s in enumerate(raw_steps)]\n",
    "\n",
    "            # ── (2) compute rewards ───────────────────────────────────────────────────\n",
    "            ori = csr(sample[\"problem\"], rollout_prompt, steps, gold_ans)\n",
    "            ptb = psr(sample[\"problem\"], rollout_prompt, steps, gold_ans, use_llm)\n",
    "            if len(ptb) != len(ori):\n",
    "                ptb = ptb[: len(ori)]\n",
    "            contrib = [round(o - p, 4) for o, p in zip(ori, ptb)]\n",
    "\n",
    "            # ── (3) Append entry ───────────────────────────────────────────\n",
    "            entry = {\n",
    "                \"question\":      sample[\"problem\"],\n",
    "                \"completion\":    steps,\n",
    "                \"ori_rewards\":   ori,\n",
    "                \"ptb_rewards\":   ptb,\n",
    "                \"contributions\": contrib,\n",
    "                \"answer\":        gold_ans,\n",
    "                \"gold_answer\":   gold_ans,\n",
    "                \"level\":         sample[\"level\"],\n",
    "                \"type\":          sample[\"type\"],\n",
    "            }\n",
    "            dataset.append(entry)\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcr = MCReward(config=cfg, model=model, tokenizer=tokenizer)\n",
    "math_dataset = mcr.build_datasets_math_vllm(split=\"test\",take=2)\n",
    "math_dataset[1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
