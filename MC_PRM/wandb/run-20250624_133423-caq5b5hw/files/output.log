Traceback (most recent call last):
  File "/home/leena/ccc_eval/mcts_prm/PRMDataset/main.py", line 41, in <module>
    main()
    ~~~~^^
  File "/home/leena/ccc_eval/mcts_prm/PRMDataset/main.py", line 37, in main
    history = trainer.fit(gsm8k_train, gsm8k_val)
  File "/home/leena/ccc_eval/mcts_prm/PRMDataset/prmtrainer.py", line 127, in fit
    tr_loss = self._run_epoch(train_loader, train=True,  epoch_idx=ep)
  File "/home/leena/ccc_eval/mcts_prm/PRMDataset/prmtrainer.py", line 90, in _run_epoch
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "/home/leena/anaconda3/envs/peer/lib/python3.13/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/leena/anaconda3/envs/peer/lib/python3.13/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/leena/anaconda3/envs/peer/lib/python3.13/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
