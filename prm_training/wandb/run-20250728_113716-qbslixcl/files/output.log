  0%|                                                                                                                                                                 | 0/3008 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/leena/anaconda3/envs/prm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
  7%|█████████▋                                                                                                                                        | 200/3008 [1:26:28<20:18:58, 26.05s/it]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
{'loss': 0.2454, 'grad_norm': 5.509692668914795, 'learning_rate': 6.490066225165563e-05, 'epoch': 0.07}
{'loss': 0.3213, 'grad_norm': 15.25051498413086, 'learning_rate': 0.00013112582781456955, 'epoch': 0.13}
{'loss': 0.1397, 'grad_norm': 3.80236554145813, 'learning_rate': 0.00019735099337748346, 'epoch': 0.2}
{'loss': 0.0996, 'grad_norm': 0.2729063034057617, 'learning_rate': 0.00019986073854859012, 'epoch': 0.27}
 20%|█████████████████████████████                                                                                                                     | 600/3008 [5:00:59<17:26:48, 26.08s/it]/home/leena/anaconda3/envs/prm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)                                                                                                                                                                   
{'eval_loss': 0.08599277585744858, 'eval_runtime': 647.793, 'eval_samples_per_second': 4.125, 'eval_steps_per_second': 0.516, 'epoch': 0.27}
{'loss': 0.0727, 'grad_norm': 3.6332805156707764, 'learning_rate': 0.0001994199290670147, 'epoch': 0.33}
{'loss': 0.0727, 'grad_norm': 0.7740063071250916, 'learning_rate': 0.00019867866189940056, 'epoch': 0.4}
{'loss': 0.0606, 'grad_norm': 0.808824360370636, 'learning_rate': 0.00019763917723461134, 'epoch': 0.47}
{'loss': 0.0668, 'grad_norm': 3.304919481277466, 'learning_rate': 0.00019630461650676378, 'epoch': 0.53}
{'eval_loss': 0.06004719063639641, 'eval_runtime': 647.1584, 'eval_samples_per_second': 4.129, 'eval_steps_per_second': 0.516, 'epoch': 0.53}
{'loss': 0.0649, 'grad_norm': 1.038428544998169, 'learning_rate': 0.00019467901290147702, 'epoch': 0.6}
{'loss': 0.0557, 'grad_norm': 1.2080999612808228, 'learning_rate': 0.00019276727916715312, 'epoch': 0.67}
{'loss': 0.0522, 'grad_norm': 1.5086826086044312, 'learning_rate': 0.00019057519276812472, 'epoch': 0.73}
{'loss': 0.052, 'grad_norm': 1.811754584312439, 'learning_rate': 0.00018810937842453828, 'epoch': 0.8}
{'eval_loss': 0.05415394529700279, 'eval_runtime': 634.4705, 'eval_samples_per_second': 4.211, 'eval_steps_per_second': 0.526, 'epoch': 0.8}
 40%|█████████████████████████████                                            | 1200/3008 [12:47:07<26:12:09, 52.17s/it]/home/leena/anaconda3/envs/prm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 0.0471, 'grad_norm': 0.22950343787670135, 'learning_rate': 0.00018537728809173945, 'epoch': 0.86}
{'loss': 0.0507, 'grad_norm': 1.2124333381652832, 'learning_rate': 0.000182387178439665, 'epoch': 0.93}
{'loss': 0.0493, 'grad_norm': 1.3110051155090332, 'learning_rate': 0.00017914808590030088, 'epoch': 1.0}
{'loss': 0.0389, 'grad_norm': 0.6382700204849243, 'learning_rate': 0.00017566979935861585, 'epoch': 1.06}
  return fn(*args, **kwargs)                                                                                                                                                                   
{'eval_loss': 0.0596587136387825, 'eval_runtime': 651.2488, 'eval_samples_per_second': 4.103, 'eval_steps_per_second': 0.513, 'epoch': 1.06}
{'loss': 0.0364, 'grad_norm': 0.6003386378288269, 'learning_rate': 0.00017196283056950158, 'epoch': 1.13}
{'loss': 0.0339, 'grad_norm': 0.5089476704597473, 'learning_rate': 0.00016803838239012206, 'epoch': 1.2}
{'loss': 0.0405, 'grad_norm': 0.4417782425880432, 'learning_rate': 0.00016390831492367816, 'epoch': 1.26}
{'loss': 0.0359, 'grad_norm': 2.0420191287994385, 'learning_rate': 0.0001595851096769039, 'epoch': 1.33}
{'eval_loss': 0.05595892667770386, 'eval_runtime': 1298.4709, 'eval_samples_per_second': 2.058, 'eval_steps_per_second': 0.257, 'epoch': 1.33}
{'loss': 0.0387, 'grad_norm': 0.46987080574035645, 'learning_rate': 0.00015508183183961499, 'epoch': 1.4}
{'loss': 0.0318, 'grad_norm': 0.5469185709953308, 'learning_rate': 0.00015041209080030398, 'epoch': 1.46}
{'loss': 0.0353, 'grad_norm': 1.1821285486221313, 'learning_rate': 0.0001455899990171092, 'epoch': 1.53}
{'loss': 0.0351, 'grad_norm': 0.2760309875011444, 'learning_rate': 0.00014063012936845287, 'epoch': 1.6}
{'eval_loss': 0.05040331929922104, 'eval_runtime': 1289.4968, 'eval_samples_per_second': 2.072, 'eval_steps_per_second': 0.259, 'epoch': 1.6}
 60%|███████████████████████████████████████████▋                             | 1800/3008 [22:30:20<17:21:00, 51.71s/it]/home/leena/anaconda3/envs/prm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 0.0359, 'grad_norm': 0.575874924659729, 'learning_rate': 0.00013554747111224014, 'epoch': 1.66}
{'loss': 0.0348, 'grad_norm': 0.2664738595485687, 'learning_rate': 0.0001303573845867142, 'epoch': 1.73}
{'loss': 0.0363, 'grad_norm': 1.0815778970718384, 'learning_rate': 0.00012507555478986722, 'epoch': 1.8}
{'loss': 0.0375, 'grad_norm': 1.1958122253417969, 'learning_rate': 0.00011971794397769464, 'epoch': 1.86}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 0.052219733595848083, 'eval_runtime': 1294.3669, 'eval_samples_per_second': 2.064, 'eval_steps_per_second': 0.258, 'epoch': 1.86}
{'loss': 0.0324, 'grad_norm': 0.2670871317386627, 'learning_rate': 0.00011430074342454587, 'epoch': 1.93}
{'loss': 0.0363, 'grad_norm': 0.9874671697616577, 'learning_rate': 0.00010884032449135697, 'epoch': 2.0}
{'loss': 0.0192, 'grad_norm': 1.1991746425628662, 'learning_rate': 0.00010335318914964289, 'epoch': 2.06}
{'loss': 0.0193, 'grad_norm': 0.3207871913909912, 'learning_rate': 9.785592011076962e-05, 'epoch': 2.13}
{'eval_loss': 0.04975944384932518, 'eval_runtime': 1293.3069, 'eval_samples_per_second': 2.066, 'eval_steps_per_second': 0.258, 'epoch': 2.13}
{'loss': 0.0203, 'grad_norm': 0.8297412395477295, 'learning_rate': 9.236513071122262e-05, 'epoch': 2.19}
{'loss': 0.0176, 'grad_norm': 0.9334189891815186, 'learning_rate': 8.68974147053226e-05, 'epoch': 2.26}
{'loss': 0.0161, 'grad_norm': 0.5066702961921692, 'learning_rate': 8.146929611712048e-05, 'epoch': 2.33}
{'loss': 0.0173, 'grad_norm': 0.9019251465797424, 'learning_rate': 7.609717930302506e-05, 'epoch': 2.39}
{'eval_loss': 0.05217447504401207, 'eval_runtime': 1285.9013, 'eval_samples_per_second': 2.078, 'eval_steps_per_second': 0.26, 'epoch': 2.39}
 80%|███████████████████████████████████████████████████████████               | 2400/3008 [32:14:52<8:48:23, 52.14s/it]/home/leena/anaconda3/envs/prm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 0.0185, 'grad_norm': 0.2073117196559906, 'learning_rate': 7.079729937607904e-05, 'epoch': 2.46}
{'loss': 0.0193, 'grad_norm': 0.2863333821296692, 'learning_rate': 6.558567314170636e-05, 'epoch': 2.53}
{'loss': 0.0176, 'grad_norm': 0.9821730852127075, 'learning_rate': 6.0478050693208995e-05, 'epoch': 2.59}
{'loss': 0.0169, 'grad_norm': 0.15465033054351807, 'learning_rate': 5.548986781329599e-05, 'epoch': 2.66}
  return fn(*args, **kwargs)                                                                                                  
{'eval_loss': 0.05463769659399986, 'eval_runtime': 1301.4417, 'eval_samples_per_second': 2.053, 'eval_steps_per_second': 0.257, 'epoch': 2.66}
{'loss': 0.0166, 'grad_norm': 0.15855616331100464, 'learning_rate': 5.0636199325493286e-05, 'epoch': 2.73}
{'loss': 0.0174, 'grad_norm': 0.9744199514389038, 'learning_rate': 4.593171353641026e-05, 'epoch': 2.79}
{'loss': 0.0159, 'grad_norm': 0.4509671628475189, 'learning_rate': 4.139062790654458e-05, 'epoch': 2.86}
{'loss': 0.0166, 'grad_norm': 0.2411118745803833, 'learning_rate': 3.702666608359201e-05, 'epoch': 2.93}
{'eval_loss': 0.05197589471936226, 'eval_runtime': 1302.8536, 'eval_samples_per_second': 2.051, 'eval_steps_per_second': 0.256, 'epoch': 2.93}
{'loss': 0.018, 'grad_norm': 1.0965936183929443, 'learning_rate': 3.285301642811156e-05, 'epoch': 2.99}
{'loss': 0.0091, 'grad_norm': 0.15393632650375366, 'learning_rate': 2.888229215688566e-05, 'epoch': 3.06}
{'loss': 0.0073, 'grad_norm': 0.13397164642810822, 'learning_rate': 2.5126493224426785e-05, 'epoch': 3.13}
{'loss': 0.0077, 'grad_norm': 0.11207941919565201, 'learning_rate': 2.159697005782798e-05, 'epoch': 3.19}
{'eval_loss': 0.05182211473584175, 'eval_runtime': 1297.3968, 'eval_samples_per_second': 2.06, 'eval_steps_per_second': 0.257, 'epoch': 3.19}
100%|███████████████████████████████████████████████████████████████████████████▊| 3000/3008 [41:58:07<06:54, 51.79s/it]/home/leena/anaconda3/envs/prm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 0.0078, 'grad_norm': 0.18384502828121185, 'learning_rate': 1.8304389254555244e-05, 'epoch': 3.26}
{'loss': 0.0094, 'grad_norm': 0.8386818766593933, 'learning_rate': 1.5258701346846215e-05, 'epoch': 3.32}
{'loss': 0.0081, 'grad_norm': 0.3935950994491577, 'learning_rate': 1.2469110730134848e-05, 'epoch': 3.39}
{'loss': 0.0086, 'grad_norm': 0.21841560304164886, 'learning_rate': 9.944047846381366e-06, 'epoch': 3.46}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 0.05199410021305084, 'eval_runtime': 1298.8595, 'eval_samples_per_second': 2.057, 'eval_steps_per_second': 0.257, 'epoch': 3.46}
{'loss': 0.0087, 'grad_norm': 0.261489599943161, 'learning_rate': 7.69114370637284e-06, 'epoch': 3.52}
{'loss': 0.0076, 'grad_norm': 0.26913052797317505, 'learning_rate': 5.7172068279901734e-06, 'epoch': 3.59}
{'loss': 0.008, 'grad_norm': 0.1999831348657608, 'learning_rate': 4.028202660137126e-06, 'epoch': 3.66}
{'loss': 0.0087, 'grad_norm': 0.1675122082233429, 'learning_rate': 2.6292355545140645e-06, 'epoch': 3.72}
{'eval_loss': 0.052264463156461716, 'eval_runtime': 1291.764, 'eval_samples_per_second': 2.068, 'eval_steps_per_second': 0.259, 'epoch': 3.72}
{'loss': 0.0073, 'grad_norm': 0.22655244171619415, 'learning_rate': 1.5245333397197803e-06, 'epoch': 3.79}
{'loss': 0.0076, 'grad_norm': 0.1370895802974701, 'learning_rate': 7.174345443001551e-07, 'epoch': 3.86}
{'loss': 0.0083, 'grad_norm': 0.5740289688110352, 'learning_rate': 2.1037830735690655e-07, 'epoch': 3.92}
{'loss': 0.0073, 'grad_norm': 0.5381215214729309, 'learning_rate': 4.897007207649295e-09, 'epoch': 3.99}
{'eval_loss': 0.052040670067071915, 'eval_runtime': 1285.8527, 'eval_samples_per_second': 2.078, 'eval_steps_per_second': 0.26, 'epoch': 3.99}
100%|████████████████████████████████████████████████████████████████████████████| 3008/3008 [42:03:19<00:00, 66.03s/it]There were unexpected keys in the checkpoint model loaded: ['backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.weight.absmax', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.weight.quant_map', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.mlp.up_proj.weight.absmax', 'backbone.base_model.model.model.layers.0.mlp.up_proj.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.mlp.up_proj.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.mlp.up_proj.weight.quant_map', 'backbone.base_model.model.model.layers.0.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.mlp.down_proj.weight.absmax', 'backbone.base_model.model.model.layers.0.mlp.down_proj.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.mlp.down_proj.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.mlp.down_proj.weight.quant_map', 'backbone.base_model.model.model.layers.0.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.
100%|████████████████████████████████████████████████████████████████████████████| 3008/3008 [42:04:18<00:00, 50.35s/it]
{'train_runtime': 151460.8005, 'train_samples_per_second': 0.635, 'train_steps_per_second': 0.02, 'train_loss': 0.03956024412145006, 'epoch': 4.0}
